{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3f9572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Core API 1.2.4.rc1: setting Data Core Env to Environment.Shanghai\n"
     ]
    }
   ],
   "source": [
    "import os, time, multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from data_core import GenericTabularData\n",
    "\n",
    "# from home_utils.home_utils import job_helper\n",
    "import white_simv2_light.lighter as lt\n",
    "from white_simv2_light.utils import utils\n",
    "\n",
    "try:\n",
    "    from utils.plotterHope import *\n",
    "    import utils.pyHope as ph\n",
    "except Exception as _e:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(_e)\n",
    "    \n",
    "_cached = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243707e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-19 16:35:58 [Lighter] [INFO] [hkg_po_400mls05 processing] Total of 1 PO Setups\n",
      "2023-07-19 16:35:58 [Lighter] [INFO] [hkg_po_400mls05 processing] START p000\n",
      "explanatory: True\n",
      "figures: True\n",
      "Total of 1 Exec Experiments\n",
      "2023-07-19 16:36:00 [Lighter] [INFO] [init] Loaded mkt hkg\n",
      "2023-07-19 16:36:00 [Lighter] [INFO] [init] rprefix /strat_hope/results_eq_hkg/hkg_po_400mls05/4yi_0ms_e00p000_{}/ pool strat_hope ns results_eq_hkg\n",
      "2023-07-19 16:36:00 [Lighter] [INFO] [init] date_dict /home/hope/sim/analysis/date_dict/hkg_eq_20210530_20230530_s13_b10.json\n",
      "2023-07-19 16:36:00 [Lighter] [INFO] [init] A total of 492 days from 2021-05-31 to 2023-05-30\n",
      "2023-07-19 16:36:00 [Lighter] [WARNING] [prepare] Estimated to take 3.9 minutes\n",
      "2023-07-19 16:36:15 [Lighter] [INFO] [prepare] s00 done; it took 14.79 seconds.\n",
      "2023-07-19 16:36:29 [Lighter] [INFO] [prepare] s01 done; it took 14.17 seconds.\n",
      "2023-07-19 16:36:43 [Lighter] [INFO] [prepare] s02 done; it took 13.80 seconds.\n",
      "2023-07-19 16:36:55 [Lighter] [INFO] [prepare] s03 done; it took 12.33 seconds.\n",
      "2023-07-19 16:37:06 [Lighter] [INFO] [prepare] s04 done; it took 10.96 seconds.\n",
      "2023-07-19 16:37:17 [Lighter] [INFO] [prepare] s05 done; it took 11.06 seconds.\n",
      "2023-07-19 16:37:30 [Lighter] [INFO] [prepare] s06 done; it took 12.72 seconds.\n",
      "2023-07-19 16:37:41 [Lighter] [INFO] [prepare] s07 done; it took 11.46 seconds.\n",
      "2023-07-19 16:37:54 [Lighter] [INFO] [prepare] s08 done; it took 13.02 seconds.\n",
      "2023-07-19 16:38:09 [Lighter] [INFO] [prepare] s09 done; it took 14.18 seconds.\n",
      "2023-07-19 16:38:21 [Lighter] [INFO] [prepare] s10 done; it took 12.73 seconds.\n",
      "2023-07-19 16:38:35 [Lighter] [INFO] [prepare] s11 done; it took 13.96 seconds.\n",
      "2023-07-19 16:38:44 [Lighter] [INFO] [prepare] s12 done; it took 9.26 seconds.\n",
      "[2023-07-19 16:38:48.274] [DATA_CORE] [warning] Invalid: Unable to merge: Field volume has incompatible types: double vs int64\n",
      "2023-07-19 16:38:49 [Lighter] [WARNING] [_d_inventory cell] Estimated to take 0.21 minutes\n",
      "2023-07-19 16:38:58 [Lighter] [INFO] [_d_inventory cell] 492 of 492 days loaded; it took 9.43 seconds.\n",
      "2023-07-19 16:38:58 [Lighter] [WARNING] [_m_orders cell] Estimated to take 0.62 minutes\n",
      "2023-07-19 16:39:54 [Lighter] [INFO] [_m_orders cell] 492 of 492 days loaded; it took 56.07 seconds.\n",
      "2023-07-19 16:39:54 [Lighter] [WARNING] [post_processing cell] Estimated to take less than 0.1 seconds.\n",
      "2023-07-19 16:39:54 [Lighter] [INFO] [post_processing cell] 492 of 492 days loaded; it took 0.07 seconds.\n",
      "2023-07-19 16:39:54 [Lighter] [INFO] [iter0 DONE] RET 12.71 bps / TO 20.49 pct\n",
      "2023-07-19 16:39:54 [Lighter] [INFO] [hkg_po_400mls05 logging] result_daily.csv\n",
      "2023-07-19 16:39:54 [Lighter] [INFO]          date  sod_cfe  sod_mfe  eod_cfe  eod_mfe  eod_lmv  eod_smv  \\\n",
      "run_num                                                               \n",
      "0         482        1        1      482      482      482      482   \n",
      "\n",
      "         sod_lmv_holding  eod_lmv_holding  sod_smv_holding  eod_smv_holding  \\\n",
      "run_num                                                                       \n",
      "0                    482              482              482              482   \n",
      "\n",
      "         pnl_raw  ret_raw  pnl_holding  ret_holding  ret_trading  \\\n",
      "run_num                                                            \n",
      "0            482      482          482          482          482   \n",
      "\n",
      "         eod_lmv_ratio  eod_smv_ratio  turnover  turnover_long  turnover_sell  \\\n",
      "run_num                                                                         \n",
      "0                  482            482       482            482            482   \n",
      "\n",
      "         turnover_short  \n",
      "run_num                  \n",
      "0                   482  \n",
      "2023-07-19 16:39:54 [Lighter] [INFO] [hkg_po_400mls05 logging] summary.csv\n",
      "2023-07-19 16:39:54 [Lighter] [INFO] [hkg_po_400mls05 logging] explanatory/day_df_hkg_po_expXX.csv\n",
      "2023-07-19 16:39:55 [Lighter] [INFO] [hkg_po_400mls05 logging] figures/return_eXX.png and figures/turnover_eXX.png\n",
      "2023-07-19 16:39:55 [Lighter] [INFO] [hkg_po_400mls05 processing] DONE in 3.95 minutes\n"
     ]
    }
   ],
   "source": [
    "burnin = 10\n",
    "_cap, _n_dir = 4e8, 4\n",
    "_dir_dict = {\n",
    "    \"long\": 1,\n",
    "    \"sell\": -1,\n",
    "    \"short\": -2,\n",
    "}\n",
    "_write_explanatory = True\n",
    "_write_figures = True\n",
    "user_remote = \"hopec\"\n",
    "login_node = \"10.8.64.176\"\n",
    "\n",
    "\n",
    "#######\n",
    "market = \"hkg\"\n",
    "algo = \"po\"\n",
    "exp_name = \"{}_{}_400mls05\".format(market, algo)\n",
    "_pre_prefix = \"4yi_0ms_e%s\"\n",
    "_pool, _ns = \"strat_hope\", \"results_eq_{}\".format(market)\n",
    "_prefix_stem = \"/strat_hope/results_eq_%s/%s/%s/\"\n",
    "_iterlist = sorted(set(range(1)) - set([]))\n",
    "_use_old_po_search = False\n",
    "\n",
    "date_dict = \"/home/hope/sim/analysis/date_dict/hkg_eq_20210530_20230530_s13_b10.json\"\n",
    "_po_search = True\n",
    "_iterlist_pocfg = [\n",
    "    \"p{}\".format(str(_iter).zfill(3)) for \\\n",
    "    _iter in sorted(set(range(1)) - set([]))\n",
    "] if _po_search else [\"\"]\n",
    "\n",
    "if market == \"hkg\":\n",
    "    _univ_bm = 101200001\n",
    "    comm = .00155\n",
    "elif market == \"twn\":\n",
    "    _univ_bm = 101300001\n",
    "    comm = .0018 # avg\n",
    "elif market == \"kor\":\n",
    "    _univ_bm = 101400002\n",
    "    comm = .0014 # avg\n",
    "\n",
    "lt.logging.info(\n",
    "    \"[%s processing] Total of %i PO Setups\",\n",
    "    exp_name,\n",
    "    len(list(_iterlist_pocfg)),\n",
    ")\n",
    "for _pocfg in _iterlist_pocfg:\n",
    "    sec_prefix = _pre_prefix + \"%s_{}\"%(_pocfg)\n",
    "\n",
    "    lt.logging.info(\n",
    "        \"[%s processing] START %s\\nexplanatory: %s\\nfigures: %s\\nTotal of %i Exec Experiments\",\n",
    "        exp_name,\n",
    "        _pocfg,\n",
    "        _write_explanatory,\n",
    "        _write_figures,\n",
    "        len(list(_iterlist)),\n",
    "    )\n",
    "    time_total = time.time()\n",
    "    #######\n",
    "\n",
    "\n",
    "    _dir_result = \\\n",
    "        \"/home/hope/sim/analysis/results/{}/{}/{}\".format(\n",
    "            market,\n",
    "            exp_name,\n",
    "            _pocfg\n",
    "        )\n",
    "    os.makedirs(_dir_result, exist_ok = True)\n",
    "    _dir_remote = \\\n",
    "        \"/home/hopec/sim/{}\".format(exp_name)\n",
    "    try:\n",
    "        os.system(\n",
    "            \"scp {}@{}:{} {}\"\\\n",
    "            .format(\n",
    "                user_remote,\n",
    "                login_node,\n",
    "                os.path.join(\n",
    "                    _dir_remote,\n",
    "                    \"experiment_map_{}_{}.json\".format(market, exp_name)\n",
    "                ),\n",
    "                _dir_result\n",
    "            )\n",
    "        )\n",
    "    except Exception as _e:\n",
    "        lt.logging.warning(\n",
    "            \"[pre_processing cell] Remote experiment setup file didn't copy; %s\",\n",
    "            _e\n",
    "        )\n",
    "\n",
    "\n",
    "    _d_df = []\n",
    "    for _i in _iterlist:\n",
    "        run_prefix = \\\n",
    "            _prefix_stem\\\n",
    "            %(\n",
    "                market,\n",
    "                exp_name,\n",
    "                sec_prefix%(str(_i).zfill(2))\n",
    "            )\n",
    "\n",
    "        lighter = lt.Lighter(\n",
    "            market,\n",
    "            run_prefix,\n",
    "            date_dict,\n",
    "            pool = _pool,\n",
    "            ns = _ns,\n",
    "            cap = _cap\n",
    "        )\n",
    "        if not _cached:\n",
    "            lighter.prepare()\n",
    "\n",
    "            _s_bar1m = lighter._s_bar1m\n",
    "            _s_eod = lighter._s_eod\n",
    "            _s_beta = lighter._s_beta\n",
    "            _ddict_full = lighter._ddict_full\n",
    "            \n",
    "            try:\n",
    "                _ret_idx = GenericTabularData(\n",
    "                    region = lighter._mkt,\n",
    "                    asset = \"idx\",\n",
    "                    dataset = \"md_eod\",\n",
    "                    univ = [_univ_bm],\n",
    "                    start_date = min(lighter._date_list),\n",
    "                    end_date = max(lighter._date_list)\n",
    "                ).as_data_frame()\n",
    "                _ret_idx[\"date\"] = _ret_idx[\"yyyymmdd\"]\n",
    "                \n",
    "            except:\n",
    "                _ret_idx = None\n",
    "\n",
    "            _cached = True\n",
    "\n",
    "        else:\n",
    "            lighter._s_bar1m = _s_bar1m\n",
    "            lighter._s_eod = _s_eod\n",
    "            lighter._s_beta = _s_beta\n",
    "            lighter._ddict_full = _ddict_full\n",
    "\n",
    "        #\n",
    "        time0 = time.time()\n",
    "        lt.logging.warning(\n",
    "            \"[_d_inventory cell] Estimated to take %.2f minutes\",\n",
    "            .025 * len(lighter._date_list) / 60\n",
    "        )\n",
    "\n",
    "        if lighter._d_inventory is not None:\n",
    "            lt.logging.warning(\n",
    "                \"[_d_inventory cell] Table exists; force reload.\"\n",
    "            )\n",
    "\n",
    "        def _func_to_map(_date):\n",
    "            _dfi = lighter._get_inventory_details(_date)\n",
    "            return _dfi\n",
    "\n",
    "        with multiprocessing.Pool(8) as P:\n",
    "            _l_res = P.map(_func_to_map, lighter._date_list)\n",
    "            P.close()\n",
    "            P.join()\n",
    "        _df = pd.concat(_l_res)\n",
    "        _df = _df.sort_values(\n",
    "            by = [\"date\"]\n",
    "        ).reset_index(drop = True)\n",
    "        lighter._d_inventory = _df\n",
    "        lt.logging.info(\n",
    "            \"[_d_inventory cell] %i of %i days loaded; it took %.2f seconds.\",\n",
    "            lighter._d_inventory.date.nunique(),\n",
    "            len(lighter._date_list),\n",
    "            time.time() - time0\n",
    "        )\n",
    "\n",
    "        #\n",
    "        time0 = time.time()\n",
    "        lt.logging.warning(\n",
    "            \"[_m_orders cell] Estimated to take %.2f minutes\",\n",
    "            .076 * len(lighter._date_list) / 60\n",
    "        )\n",
    "\n",
    "        if lighter._m_orders is not None:\n",
    "            lt.logging.warning(\n",
    "                \"[_m_orders cell] Table exists; force reload.\"\n",
    "            )\n",
    "\n",
    "        def _func_to_map(_date):\n",
    "            _dfi = lighter._get_order_details_fast(_date, extra_grouping = [\"orderDirection\"])\n",
    "            return _dfi\n",
    "\n",
    "        with multiprocessing.Pool(8) as P:\n",
    "            _l_res = P.map(_func_to_map, lighter._date_list)\n",
    "            P.close()\n",
    "            P.join()\n",
    "        _df = pd.concat(_l_res)\n",
    "        _df = _df.sort_values(\n",
    "            by = [\"date\", \"minute\"]\n",
    "        ).reset_index(drop = True)\n",
    "        lighter._m_orders = _df\n",
    "        lt.logging.info(\n",
    "            \"[_m_orders cell] %i of %i days loaded; it took %.2f seconds.\",\n",
    "            lighter._m_orders.date.nunique(),\n",
    "            len(lighter._date_list),\n",
    "            time.time() - time0\n",
    "        )\n",
    "\n",
    "        #\n",
    "        time0 = time.time()\n",
    "        lt.logging.warning(\n",
    "            \"[post_processing cell] Estimated to take less than 0.1 seconds.\"\n",
    "        )\n",
    "        _df = lighter._d_inventory.copy()\n",
    "        _df[\"pnl_raw\"] = \\\n",
    "            _df.eod_lmv + \\\n",
    "            _df.eod_cfe - \\\n",
    "            _df.sod_cfe - \\\n",
    "            (_df.eod_smv + \\\n",
    "             _df.eod_mfe - \\\n",
    "             _df.sod_mfe)\n",
    "        _df[\"ret_raw\"] = _df.pnl_raw / _cap\n",
    "        _df[\"pnl_holding\"] = \\\n",
    "            _df.eod_lmv_holding - \\\n",
    "            _df.sod_lmv_holding - \\\n",
    "            (_df.eod_smv_holding - \\\n",
    "             _df.sod_smv_holding)\n",
    "        _df[\"ret_holding\"] = _df.pnl_holding / _cap\n",
    "        _df[\"ret_trading\"] = _df.ret_raw - _df.ret_holding\n",
    "        _df_orders = lighter._m_orders.copy()\n",
    "        _df[\"eod_lmv_ratio\"] = _df.eod_lmv / _cap\n",
    "        _df[\"eod_smv_ratio\"] = _df.eod_smv / _cap\n",
    "        _tmp_to = (_df_orders.groupby([\"date\"])[\"tradeNotional_final\"].sum() / \\\n",
    "            _n_dir / _cap).reset_index()\n",
    "        _tmp_to.rename({\n",
    "            \"tradeNotional_final\": \"turnover\"\n",
    "        }, axis = 1, inplace = True)\n",
    "        _df = pd.merge(\n",
    "            _df,\n",
    "            _tmp_to,\n",
    "            on = [\"date\"],\n",
    "            how = \"left\"\n",
    "        )\n",
    "        _df[\"turnover\"] = _df[\"turnover\"].fillna(0.)\n",
    "        for _ikey, _idir in _dir_dict.items():\n",
    "            try:\n",
    "                _tmp_dir = (_df_orders[_df_orders.orderDirection == _idir]\\\n",
    "                    .groupby([\"date\"])[\"tradeNotional_final\"].sum() / \\\n",
    "                    _cap).reset_index()\n",
    "                _tmp_dir.rename({\n",
    "                    \"tradeNotional_final\": \"turnover_{}\".format(_ikey)\n",
    "                }, axis = 1, inplace = True)\n",
    "                _df = pd.merge(\n",
    "                    _df,\n",
    "                    _tmp_dir,\n",
    "                    on = [\"date\"],\n",
    "                    how = \"left\"\n",
    "                )\n",
    "                _df[\"turnover_{}\".format(_ikey)] = \\\n",
    "                    _df[\"turnover_{}\".format(_ikey)].fillna(0.)\n",
    "            except Exception as _e:\n",
    "                lt.logging.warning(\n",
    "                    \"[post_processing cell] ERR processing dir %i; %s\",\n",
    "                    _idir,\n",
    "                    _e\n",
    "                )\n",
    "                continue\n",
    "        lt.logging.info(\n",
    "            \"[post_processing cell] %i of %i days loaded; it took %.2f seconds.\",\n",
    "            _df.date.nunique(),\n",
    "            len(lighter._date_list),\n",
    "            time.time() - time0\n",
    "        )\n",
    "\n",
    "        #\n",
    "        lt.logging.info(\n",
    "            \"[iter%i DONE] RET %.2f bps / TO %.2f pct\",\n",
    "            _i,\n",
    "            _df.iloc[burnin:][\"ret_raw\"].mean() * 10000,\n",
    "            _df.iloc[burnin:][\"turnover\"].mean() * 100\n",
    "        )\n",
    "\n",
    "\n",
    "        _df[\"run_num\"] = _i\n",
    "        _d_df.append(_df.iloc[burnin:])\n",
    "\n",
    "    _d_df = pd.concat(_d_df)\n",
    "\n",
    "    #\n",
    "    _d_df.to_csv(\n",
    "        os.path.join(_dir_result, \"result_daily.csv\"),\n",
    "        index = False\n",
    "    )\n",
    "    lt.logging.info(\n",
    "        \"[%s logging] result_daily.csv\",\n",
    "        exp_name\n",
    "    )\n",
    "    lt.logging.info(\n",
    "        \"%s\",\n",
    "        _d_df.groupby([\"run_num\"]).nunique()\n",
    "    )\n",
    "\n",
    "    #\n",
    "    _summary = utils.summarize(\n",
    "        _d_df, \n",
    "        comm,\n",
    "        _ret_idx = _ret_idx\n",
    "    )\n",
    "    _summary.to_csv(\n",
    "        os.path.join(_dir_result, \"summary.csv\"),\n",
    "        index = False\n",
    "    )\n",
    "    lt.logging.info(\n",
    "        \"[%s logging] summary.csv\",\n",
    "        exp_name\n",
    "    )\n",
    "\n",
    "    #\n",
    "    if _write_explanatory:\n",
    "        _dir_explanatory = \\\n",
    "            os.path.join(_dir_result, \"explanatory\")\n",
    "        os.makedirs(_dir_explanatory, exist_ok = True)\n",
    "\n",
    "        for _i in _iterlist:\n",
    "            _df = _d_df[_d_df.run_num == _i].copy()\n",
    "            _df = _df.sort_values(by = [\"date\"]).reset_index(drop = True)\n",
    "\n",
    "            _df_out = _df[[\"date\"]].copy()\n",
    "            _df_out[\"turnover_total\"] = _df.turnover * _n_dir * _cap\n",
    "            _df_out[\"ret_raw\"] = _df.ret_raw * _cap + _df_out.turnover_total * comm\n",
    "            _df_out[\"ret_trading\"] = _df.ret_trading * _cap + _df_out.turnover_total * comm\n",
    "            _df_out[\"ret_holding\"] = _df.ret_holding * _cap\n",
    "\n",
    "            _df_out.to_csv(\n",
    "                os.path.join(\n",
    "                    _dir_explanatory,\n",
    "                    \"day_df_{}_{}_exp{}.csv\"\\\n",
    "                    .format(\n",
    "                        market,\n",
    "                        algo,\n",
    "                        str(_i).zfill(2)\n",
    "                    )\n",
    "                ),\n",
    "                index = False\n",
    "            )\n",
    "\n",
    "        lt.logging.info(\n",
    "            \"[%s logging] explanatory/day_df_%s_%s_expXX.csv\",\n",
    "            exp_name,\n",
    "            market,\n",
    "            algo,\n",
    "        )\n",
    "\n",
    "    if _write_figures:\n",
    "        _dir_explanatory = \\\n",
    "            os.path.join(_dir_result, \"figures\")\n",
    "        os.makedirs(_dir_explanatory, exist_ok = True)\n",
    "\n",
    "        for _i in _iterlist:\n",
    "            plt.figure()\n",
    "\n",
    "            plt.plot(_d_df[_d_df.run_num == _i].ret_raw.cumsum().values * 100,\n",
    "                     label = \"Total Return Exp{}\\nmean = {:.2f} bps\"\\\n",
    "                         .format(\n",
    "                             str(_i).zfill(2),\n",
    "                             _d_df[_d_df.run_num == _i].ret_raw.mean() * 10000\n",
    "                         ))\n",
    "            plt.plot(_d_df[_d_df.run_num == _i].ret_holding.cumsum().values * 100,\n",
    "                     label = \"Holding Return Exp{}\\nmean = {:.2f} bps\"\\\n",
    "                         .format(\n",
    "                             str(_i).zfill(2),\n",
    "                             _d_df[_d_df.run_num == _i].ret_holding.mean() * 10000\n",
    "                         ))\n",
    "            plt.plot(_d_df[_d_df.run_num == _i].ret_trading.cumsum().values * 100,\n",
    "                     label = \"Trading Return Exp{}\\nmean = {:.2f} bps\"\\\n",
    "                         .format(\n",
    "                             str(_i).zfill(2),\n",
    "                             _d_df[_d_df.run_num == _i].ret_trading.mean() * 10000\n",
    "                         ))\n",
    "\n",
    "            plt.legend()\n",
    "\n",
    "            try:\n",
    "                ax = plt.gca()\n",
    "                ph.plot_date_ticks(ax, _d_df[_d_df.run_num == _i].date.values, minTicks = 9)\n",
    "            except Exception as _e:\n",
    "                print(_e)\n",
    "\n",
    "            plt.ylabel(\"Cumulative Return [%]\")\n",
    "\n",
    "            plt.savefig(\n",
    "                os.path.join(\n",
    "                    _dir_explanatory,\n",
    "                    \"return_e{}.png\".format(str(_i).zfill(2)))\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "            #\n",
    "            plt.figure()\n",
    "            plt.plot(_d_df[_d_df.run_num == _i].turnover.values * 100,\n",
    "                     label = \"Average Turnover Exp{}\\nmean = {:.2f} pct\"\\\n",
    "                        .format(\n",
    "                             str(_i).zfill(2),\n",
    "                             _d_df[_d_df.run_num == _i].turnover.mean() * 100\n",
    "                         ),\n",
    "                     color = \"k\",\n",
    "                     zorder = 999,\n",
    "                     lw = 3)\n",
    "            plt.plot(_d_df[_d_df.run_num == _i].turnover_long.values * 100,\n",
    "                     label = \"LONG Turnover Exp{}\\nmean = {:.2f} pct\"\\\n",
    "                        .format(\n",
    "                             str(_i).zfill(2),\n",
    "                             _d_df[_d_df.run_num == _i].turnover_long.mean() * 100\n",
    "                         ))\n",
    "            plt.plot(_d_df[_d_df.run_num == _i].turnover_sell.values * 100,\n",
    "                     label = \"SELL Turnover Exp{}\\nmean = {:.2f} pct\"\\\n",
    "                        .format(\n",
    "                             str(_i).zfill(2),\n",
    "                             _d_df[_d_df.run_num == _i].turnover_sell.mean() * 100\n",
    "                         ))\n",
    "            plt.plot(_d_df[_d_df.run_num == _i].turnover_short.values * 100,\n",
    "                     label = \"SHORT Turnover Exp{}\\nmean = {:.2f} pct\"\\\n",
    "                        .format(\n",
    "                             str(_i).zfill(2),\n",
    "                             _d_df[_d_df.run_num == _i].turnover_short.mean() * 100\n",
    "                         ))\n",
    "\n",
    "            plt.legend(ncol = 2)\n",
    "\n",
    "            try:\n",
    "                ax = plt.gca()\n",
    "                ph.plot_date_ticks(ax, _d_df[_d_df.run_num == _i].date.values, minTicks = 9)\n",
    "            except Exception as _e:\n",
    "                print(_e)\n",
    "\n",
    "            plt.ylabel(\"Turnover [%]\")\n",
    "\n",
    "            plt.savefig(\n",
    "                os.path.join(\n",
    "                    _dir_explanatory,\n",
    "                    \"turnover_e{}.png\".format(str(_i).zfill(2)))\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "        lt.logging.info(\n",
    "            \"[%s logging] figures/return_eXX.png and figures/turnover_eXX.png\",\n",
    "            exp_name,\n",
    "        )\n",
    "\n",
    "    time_total = time.time() - time_total\n",
    "    lt.logging.info(\n",
    "        \"[%s processing] DONE in %.2f minutes\",\n",
    "        exp_name,\n",
    "        time_total / 60\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6cd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
